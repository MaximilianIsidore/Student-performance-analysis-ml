# -*- coding: utf-8 -*-
"""Copy of student-performance-analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18MrgGztqrwhpgv9rXM9pm2c2I9BdgI3t
"""

import numpy as np
import pandas as pd

data = pd.read_csv("Student_Performance.csv")
print(data.shape)
print(data.head())

data.describe()

columns = data.columns
columns

data.isnull().sum()

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
data['Extracurricular Activities'] = encoder.fit_transform(data['Extracurricular Activities'])
data.head()

features = data.drop("Performance Index", axis = 1)
target = data["Performance Index"]

import seaborn as sns
import matplotlib.pyplot as plt


# 1. Heatmap (correlation matrix)
plt.figure(figsize=(8,6))
sns.heatmap(data.corr(), annot=True, cmap="coolwarm", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
sns.boxplot(data=features)
plt.xticks(rotation=45)
plt.title("Box Plot of student performance Dataset Features")
plt.show()

# 3. Pair Plot (pairwise relationships)
sns.pairplot(data)

for column in columns:
  q1 = data[column].quantile(0.25)
  q3 = data[column].quantile(0.75)
  iqr = q3 - q1
  lb = q1 - 1.5*iqr
  ub = q3 + 1.5*iqr
  df = data[(data[column] >= lb) & (data[column] <= ub)]

print(data.head())
print(data.size)
print(data.shape)

data.duplicated().sum()

data = data.drop_duplicates()

X = data.drop("Performance Index", axis=1)
y = data["Performance Index"]

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split


scaler = MinMaxScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Train-test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

from sklearn.linear_model import LinearRegression
reg = LinearRegression()

reg.fit(X_train, y_train)

print(reg.coef_)
print(reg.intercept_)

from sklearn.metrics import mean_squared_error, r2_score
y_pred = reg.predict(X_test)
print(X_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(mse)
print(r2)

import numpy as np

# Min and Max values from your dataset
min_values = {
    "Hours Studied": 1,
    "Previous Scores": 40,
    "Extracurricular Activities": 0,   # stays 0/1
    "Sleep Hours": 4,
    "Sample Question Papers Practiced": 0
}

max_values = {
    "Hours Studied": 9,
    "Previous Scores": 99,
    "Extracurricular Activities": 1,   # stays 0/1
    "Sleep Hours": 9,
    "Sample Question Papers Practiced": 9
}

def min_max_normalize(x, feature, min_vals, max_vals):
    return (x - min_vals[feature]) / (max_vals[feature] - min_vals[feature])

hours_studied = int(input("Enter hours studied: "))
previous_scores = int(input("Enter previous scores: "))
extracurricular = input("Enter extracurricular activities: ")
extracurricular = 1 if extracurricular == "yes" else 0

sleep_hours = int(input("Enter sleep hours: "))
sample_papers = int(input("Enter number of sample question papers practiced: "))

# Put inputs into a numpy array (reshape for sklearn model)
X_new = np.array([[hours_studied, previous_scores, extracurricular, sleep_hours, sample_papers]])

X_normalized = np.array([[
    min_max_normalize(hours_studied, "Hours Studied", min_values, max_values),
    min_max_normalize(previous_scores, "Previous Scores", min_values, max_values),
    extracurricular,
    min_max_normalize(sleep_hours, "Sleep Hours", min_values, max_values),
    min_max_normalize(sample_papers, "Sample Question Papers Practiced", min_values, max_values)
]])

print("Preformance index = ", reg.predict(X_normalized))

print(reg.coef_)
print(reg.intercept_)

import pickle as pkl
pkl.dump(reg, open('model.pkl', 'wb'))